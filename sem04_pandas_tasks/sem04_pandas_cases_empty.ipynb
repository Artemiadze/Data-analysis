{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src='images/pandaearth.jpg' align='center' width=\"1100x\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Андан на экономе\n",
    "\n",
    "## Семинар 4: Аналитика продаж в pandas\n",
    "\n",
    "В этот раз мы с вами рассмотрим реальный продуктовый кейс по анализу продаж в некотором онлайн магазине. Поотвечаем на бизнес-вопросы, которые часто волнуют аналитиков в крупных компаниях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас есть данные о продажах в некотором интернет-магазине техники. \n",
    "\n",
    "- **`Order ID`** – айдишник заказа;\n",
    "    - _айдишник является уникальным номером для каждого созданного заказа и определяется в момент создания заказа_\n",
    "- **`Product`** – товар, который пользователь добавил в свой заказ;\n",
    "    - _обратите внимание, что в одном заказе может быть несколько товаров_\n",
    "- **`Quantity Ordered`** – кол-во определенного товара в заказе;\n",
    "- **`Price Each`** – цена одного определенного товара в заказе (в долл.);\n",
    "- **`Order Date`** – дата создания заказа;\n",
    "- **`Purchase Address`** – адрес доставки заказа;\n",
    "- **`User ID`** – айдишник пользователя, сделавшего заказ.\n",
    "    - _при этом один заказ относится только к одному пользователю, то есть связка Order ID – User ID является уникальной_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sales_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предварительный анализ\n",
    "\n",
    "Перед тем, как приступать к решению конкретной задачи, нужно посмотреть на ваши данные. Понять, каким образом они устроены, какие в целом признаки у вас есть, правильно ли эти данные подгрузились, есть ли у вас пропуски, какой формат имеет каждая колонка и так далее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там по кол-ву наблюдений?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там с пропусками?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Видим, что в данных есть пропуски. Причем кажется, что по каждой колонке это одни и те же строки. В таком случае мы можем просто их удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кол-во колонок уменьшилось ровно на 545\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там по формату колонок?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Видим, что все колонки имеют тип данных `object` – это не очень хорошо, ведь мы явно знаем, что `Order ID`, `User ID` и `Quantity Ordered` должны иметь тип `int`, а цена – `float`. При этом в pandas есть специальный формат для даты и по-хорошему нужно им тоже воспользоваться для колонки `Order Date`. Скорей всего такое произошло из-за пропусков, либо из-за других проблем в колонках. Нужно будет найти их и после этого подкорректировать форматы колонок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем перевести колонку Order ID в int, получаем ошибку и разбираемся почему...\n",
    "df['Order ID'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в колонках почему-то лежат их названия, надо бы их выкинуть\n",
    "df[~df['Order ID'].str.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем только хорошие наблюдения\n",
    "df = df[df['Order ID'].str.isdigit()]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь пробуем перевести тип колонок еще раз\n",
    "df[['Order ID', 'Quantity Ordered', 'User ID']] = df[['Order ID', 'Quantity Ordered', 'User ID']].astype('float64')\n",
    "df[['Order ID', 'Quantity Ordered', 'User ID']] = df[['Order ID', 'Quantity Ordered', 'User ID']].astype('int64')\n",
    "df['Price Each'] = df['Price Each'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с датой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Order Date'] = pd.to_datetime(df['Order Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим еще раз на тип колонок\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что там с распределением признаков?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кол-во заказов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity Ordered'].hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Quantity Ordered'].hist(bins=30, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Похоже на Пуассона"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоимость заказа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим данные для графика\n",
    "df['GMV'] = df['Price Each'] * df['Quantity Ordered']\n",
    "gb = df.groupby('Order ID')['GMV'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb.hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb.hist(bins=30, log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Есть явные выбросы в районе $\\$2000$ и выше. Не будем пока их удалять, но будем держать в голове."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `.value_counts()` можно еще смотреть на распределение значений в категориальных признаках, например, можем посмотреть, какие товары чаще всего заказывали:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Product'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первых этапах не стоит сильно упарываться в предварительный анализ, пора переходить к задачам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс №1: Реклама и пиар\n",
    "\n",
    "Предположим, что перед нами стоит задача привлечения новых пользователей и удержание существующих. Для этого мы собираемся, во-первых, устраивать различные промоакции в периоды падения активности, чтобы стимулировать пользователей покупать товары, а во-вторых, запускать крупные рекламные кампании, наоборот, в период высокой активности пользователей, чтобы пользователи покупали товары именно в нашем интернет-магазине. \n",
    "\n",
    "__Как определить период, когда следует запускать разного рода акции?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно, в таких задачах _нету единственного правильного решения_. Вам нужно накидать возможные гипотезы и варианты, а затем обсудить минусы и плюсы каждого подхода. \n",
    "\n",
    "При этом нужно всегда отталкиваться от данных, которые у вас есть, и от сроков, которые вы готовы потратить на эту задачу:\n",
    "- можно построить супер новороченный предсказательный алгоритм и потратить на него полгода, а можно пару часов посидеть в пандасе и уже придумать вполне себе хорошее решение\n",
    "\n",
    "_Одно из возможных решений:_\n",
    "1. Посмотреть на динамику кол-ва заказов по дням, возможно увидим сезонность.\n",
    "2. Посмотреть распределение выручки от заказов по месяцам.\n",
    "3. Посмотреть, в какое время суток чаще всего создают заказ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Динамика кол-ва заказов по дням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Динамика выручки по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По первым двум графикам можем сказать, что \n",
    "\n",
    "> - Активность ниже всего в январе, так как посленовогодние праздники + падает летом\n",
    "> - Активность выше всего в октябре, апреле и в декабре – самые сезонные месяцы для покупки техники. Черная пятница? Новогодние праздники?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Динамика кол-ва заказов от времени суток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По третьему графику видно, что\n",
    "\n",
    "> Активность заказов начинает расти с самого утра и достигает пика на обед, а также на ранний вечер. Это часы свободного времени пользователей. Скорее всего пользователи вечером возвращаются домой с работы и у них есть время на заказы, либо в обеденное время. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что дальше? – Да что угодно! Можно закапываться в данные сколь угодно, пока не достигнете желаемых результатов, главное соблюдать баланс и не анализировать ради анализа.\n",
    "\n",
    "Например, мы можем посмотреть, в каком городе больше всего заказов и сказать, что баннеры запускать лучше там. Сгенерируйте собственную гипотезу и проверьте ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кейс №2: Рекомендации товаров\n",
    "\n",
    "Теперь предположим, что мы хотим повысить средний чек заказа. Для этого, на этапе того, как пользователь добавляет товар в корзину, мы хотим предлагать ему купить еще товары, которые скорее всего его заинтересуют, учитывая тот товар, который он уже добавил в корзину.\n",
    "\n",
    "**Как нам определить, какие товары рекомендовать конкретному пользователю?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Одно из возможных решений_ – посмотреть, какие товары пользователи покупают вместе чаще всего. Их и рекомендовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youre code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что дальше? – Да снова что угодно! \n",
    "\n",
    "Например, если у нас были бы данные о пользователях, то мы могли бы использовать признаки пользователей в составлении рекомендаций (кол-во его заказов в целом, возраст, ...). Кстати, обычно данные разбросаны в куче таблиц, поэтому вполне возможна такая ситуация, когда информация по товарам лежит в одной таблице, а информация по пользователям в другой таблице. Тогда вам нужно будет воспользоваться еще одним очень полезным приемом – __сджойнить 2 таблицы по ключу__. В pandas это можно сделать с помощью функции `pd.merge` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Небольшая история про джойны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто хранить информацию в одной таблице бывает довольно неудобно. Когда у вас очень крупная IT-компания, данных настолько много, что если их добавить в одну таблицу, работать с ней будет очень неэффективно по времени и памяти. Поэтому информацию кладут в кучу разных таблиц, а над ними строят специальные *отношения* - так называемые колонки, по которым можно эти таблицы объединять. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://community.qlik.com/legacyfs/online/87693_all-joins.png\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Student': ['Tom', 'Ujin', 'Ann', 'Polina','Sam'],\n",
    "                    'group': ['01', '02', '02', '01','02']})\n",
    "df2 = pd.DataFrame({'Name': ['Tom', 'Ujin', 'Ann', 'Polina', 'Kit'],\n",
    "                    'GPA': ['7.8', '6.4', '8.3', '9', '10']})\n",
    "display(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join по умолчанию \n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join - оставляем все, что в левой таблице\n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "pd.merge(df1, df2, left_on='Student', right_on='Name', how='outer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
